{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "dqqfa9uitzmo2twy5xdrjg"
   },
   "source": [
    "# Подготовка базы ответов для бота"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellId": "h2t6k7pvd1vx3k5alued3"
   },
   "outputs": [],
   "source": [
    "core_numbers = 4\n",
    "w2v_width = 300\n",
    "ft_width = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "cellId": "t0n09cl9c499ic3arhyik"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/jupyter/.cache/pip/wheels/fb/86/b2/277b10b1ce9f73ce15059bf6975d4547cc4ec3feeb651978e9/stop_words-2018.7.23-py3-none-any.whl\n",
      "Installing collected packages: stop-words\n",
      "Successfully installed stop-words-2018.7.23\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/stop_words already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/stop_words-2018.7.23.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cellId": "nu8e2nueg76w69zbv2w69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/jupyter/.cache/pip/wheels/4f/e8/1e/7cc9ebbfa87a3b9f8ba79408d4d31831d67eea918b679a4c07/annoy-1.17.0-cp37-cp37m-linux_x86_64.whl\n",
      "Installing collected packages: annoy\n",
      "Successfully installed annoy-1.17.0\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/annoy already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /home/jupyter/work/pyenv/annoy-1.17.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "cellId": "n47w420d80mmogeg6jl7yl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting compress_fasttext\n",
      "  Downloading compress-fasttext-0.0.6.tar.gz (9.4 kB)\n",
      "Collecting gensim>=3.8.1\n",
      "  Downloading gensim-3.8.1-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.2 MB 6.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy\n",
      "  Downloading numpy-1.19.1-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5 MB 8.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.18.1\n",
      "  Downloading scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.1 MB 8.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six>=1.5.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-3.0.0.tar.gz (113 kB)\n",
      "\u001b[K     |████████████████████████████████| 113 kB 17.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests\n",
      "  Downloading requests-2.22.0-py2.py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 5.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting chardet<3.1.0,>=3.0.2\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 18.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Downloading certifi-2020.6.20-py2.py3-none-any.whl (156 kB)\n",
      "\u001b[K     |████████████████████████████████| 156 kB 20.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting idna<2.9,>=2.5\n",
      "  Downloading idna-2.6-py2.py3-none-any.whl (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 5.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Downloading urllib3-1.24.3-py2.py3-none-any.whl (118 kB)\n",
      "\u001b[K     |████████████████████████████████| 118 kB 16.2 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: compress-fasttext, smart-open\n",
      "  Building wheel for compress-fasttext (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for compress-fasttext: filename=compress_fasttext-0.0.6-py3-none-any.whl size=13038 sha256=977abf4fc5daefade87420ad619b6e4e2cc7d7cb85301fad579009ced8ee6203\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/7b/cf/f1/0c07445d43ec1295f425d1b566b50956fecd5850a7155b90f0\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-3.0.0-py3-none-any.whl size=113977 sha256=ff17704d82d683c9482bf018d05dca740cb2408c23b0a41964e9c44bab273557\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/83/a6/12/bf3c1a667bde4251be5b7a3368b2d604c9af2105b5c1cb1870\n",
      "Successfully built compress-fasttext smart-open\n",
      "Installing collected packages: urllib3, idna, chardet, certifi, requests, numpy, smart-open, six, scipy, gensim, compress-fasttext\n",
      "Successfully installed certifi-2020.6.20 chardet-3.0.4 compress-fasttext-0.0.6 gensim-3.8.1 idna-2.6 numpy-1.19.1 requests-2.22.0 scipy-1.4.1 six-1.15.0 smart-open-3.0.0 urllib3-1.24.3\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install compress_fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "cellId": "6ediwppdq2wqtwvw09mcs"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "import annoy\n",
    "from gensim.models import Word2Vec, FastText, KeyedVectors\n",
    "import compress_fasttext\n",
    "from gensim.models.fasttext import FastTextKeyedVectors\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm    # tqdm.notebook \n",
    "from pathlib import Path\n",
    "from linecache import getline\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ju0gbubjxncasgxmt9td"
   },
   "source": [
    "## Загружаем исходный корпус вопросов и ответов (Ответы Mail.ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "cellId": "oml4hlfuzknhj3sgpchntj"
   },
   "outputs": [],
   "source": [
    "from cloud_ml.storage.api import Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "cellId": "l7riejo0p0lx95bxpl9sbq"
   },
   "outputs": [],
   "source": [
    "disk = Storage.ya_disk(application_id='8b22c6d569724e6b92xxxxxxxxxxx', application_secret='b2b380d359a54802bexxxxxxxxxxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cellId": "8kmkv1yf7zbwhkzbc6alx9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ml_kernel/kernel.py:442: UserWarning: The following variables cannot be serialized: disk\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "disk.get('Jupyter/NLP/Otvety.txt', 'Otvety.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "cellId": "2qpv7xbu6pi28kn36sbcflj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ml_kernel/kernel.py:442: UserWarning: The following variables cannot be serialized: disk\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "disk.get('Jupyter/NLP/ft_freqprune_400K_100K_pq_300.bin', 'ft_freqprune_400K_100K_pq_300.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "j8xpt608baie8w3affk58"
   },
   "source": [
    "## Word2vec эмбеддинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "cellId": "di7lt14ydfmk1zwen6zdia"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7550926it [03:54, 32140.86it/s]\n"
     ]
    }
   ],
   "source": [
    "question = None\n",
    "written = False\n",
    "\n",
    "with open(\"prepared_answers2.txt\", \"w\") as fout:\n",
    "    with open(\"Otvety.txt\", \"r\", errors='ignore') as fin:\n",
    "        for line in tqdm(fin):\n",
    "            if line.startswith(\"---\"):\n",
    "                written = False\n",
    "                continue\n",
    "            if not written and question is not None:\n",
    "                line = re.sub(r'<br>','\\n', line)\n",
    "                line = re.sub(r'<[^<]*>','', line)\n",
    "                if(len(line)>4076):\n",
    "                    tmp_line = line[:4076]\n",
    "                fout.write(question.replace(\"\\t\", \" \").strip() + \"\\t\" + line.replace(\"\\t\", \" \"))\n",
    "                written = True\n",
    "                question = None\n",
    "                continue\n",
    "            if not written:\n",
    "                question = line.strip()\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellId": "tq78wn58fb870zmvku30bw"
   },
   "outputs": [],
   "source": [
    "morpher = MorphAnalyzer()\n",
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellId": "chhxt0c7q5il5xrnbzj40f"
   },
   "outputs": [],
   "source": [
    "def preprocess_txt(line):\n",
    "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
    "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
    "    return spls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellId": "2ow2fmms50x1p91s0oev8e"
   },
   "outputs": [],
   "source": [
    "flag_w2v = False\n",
    "flag_ft = False\n",
    "\n",
    "w2v_file = Path(\"word2vec_wv.bin\")\n",
    "if w2v_file.is_file():\n",
    "#     model_w2v_wv = KeyedVectors.load(w2v_file, mmap='r')\n",
    "    model_w2v_wv = KeyedVectors.load_word2vec_format(w2v_file, binary=True)\n",
    "#     modelW2V = Word2Vec.load(w2v_file)\n",
    "    flag_w2v = True\n",
    "\n",
    "# ft_file = Path(\"fasttext_wv.bin\")\n",
    "ft_file = Path(\"ft_freqprune_400K_100K_pq_300.bin\")\n",
    "if ft_file.is_file():\n",
    "#     modelFT = FastText.load(\"fasttext.model\")\n",
    "    model_ft_wv = FastTextKeyedVectors.load(\"ft_freqprune_400K_100K_pq_300.bin\")\n",
    "    flag_ft = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "cellId": "ki641twmd8jgfgu7e9n98k"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.15978006,  0.12972822,  0.21127554,  0.29666308,  0.25573889,\n",
       "        0.1686621 , -0.05744876, -0.52107803,  0.18609457, -0.22283846,\n",
       "       -0.03836431, -0.04170422, -0.10437255, -0.29092596,  0.10090196,\n",
       "        0.33342996, -0.67721425, -0.15884957,  0.02521641, -0.33641117,\n",
       "       -0.26925578,  0.23259699,  0.13870712, -0.08089827, -0.03441673,\n",
       "        0.24143436, -0.29945117,  0.12255987,  0.09575692, -0.08634345,\n",
       "       -0.21093656, -0.34836296, -0.17476538,  0.45353659, -0.10380922,\n",
       "       -0.09972098,  0.09274811,  0.06449159, -0.06760033, -0.10698365,\n",
       "       -0.11544589, -0.39024976, -0.16776919, -0.02356622,  0.19175797,\n",
       "       -0.19430752, -0.00745214,  0.37378223,  0.06579063, -0.17072464,\n",
       "        0.14309801,  0.14525867, -0.82332072, -0.25561934, -0.00373324,\n",
       "        0.08323687, -0.18829364,  0.18259489, -0.24611599,  0.15786773,\n",
       "       -0.27496507,  0.34677877,  0.1449238 ,  0.06140086, -0.08831784,\n",
       "       -0.04187009, -0.56405255, -0.04610748, -0.28585907,  0.05999637,\n",
       "       -0.04451675,  0.51549979, -0.53300587,  0.13451668,  0.2495925 ,\n",
       "        0.3090857 ,  0.02322338, -0.03319445, -0.48081142,  0.16502423,\n",
       "       -0.09871452,  0.00337909,  0.05510282,  0.13928378,  0.22404459,\n",
       "       -0.24798716, -0.25893297,  0.09900893, -0.04817556, -0.33063456,\n",
       "       -0.122467  , -0.24986858,  0.02717431, -0.31572729, -0.3573612 ,\n",
       "        0.38759465, -0.20430269, -0.01053742, -0.06464369,  0.21284723,\n",
       "       -0.22374483, -0.0782066 ,  0.0243649 ,  0.33852726,  0.00907159,\n",
       "       -0.08040985, -0.16947049, -0.12724731,  0.02120892, -0.0926338 ,\n",
       "       -0.05269936,  0.10422701, -0.13552169, -0.17322002,  0.26209143,\n",
       "       -0.10600196, -0.57465671,  0.31749339, -0.50309295,  0.15522706,\n",
       "        0.20964767,  0.34657103,  0.40493187,  0.11390788,  0.08124474,\n",
       "       -0.05498976, -0.00603307, -0.24440988,  0.17525525, -0.06147411,\n",
       "       -0.08993466, -0.06280955, -0.2226218 ,  0.01258389, -0.03646134,\n",
       "        0.24888245,  0.1939961 ,  0.16608969, -0.19648226, -0.0328442 ,\n",
       "        0.02018351,  0.26082067,  0.02431916, -0.14203473,  0.03494841,\n",
       "       -0.09990741, -0.11709758, -0.31508452, -0.15305547,  0.00962349,\n",
       "       -0.14013155,  0.25655535, -0.00138157, -0.08293574, -0.06427295,\n",
       "        0.12155597, -0.12944133,  0.03477887, -0.03517611, -0.18349083,\n",
       "       -0.23391528,  0.30754498,  0.18244588,  0.38054132, -0.24566411,\n",
       "       -0.04610271,  0.04871203, -0.22645054, -0.05414502, -0.18122077,\n",
       "        0.03142226, -0.27159433, -0.0791276 ,  0.10508673, -0.01357799,\n",
       "       -0.08359419, -0.08663811, -0.36564598,  0.13163522,  0.36731062,\n",
       "       -0.14932645,  0.31202676,  0.26368368,  0.33576187,  0.25293983,\n",
       "        0.04408363, -0.25080536,  0.00536027,  0.11341752,  0.01770937,\n",
       "       -0.03245751, -0.07790864, -0.20003514, -0.15578536,  0.31296753,\n",
       "        0.09187346, -0.24078067, -0.1171819 , -0.21611667,  0.04542152,\n",
       "        0.20623476, -0.03002066,  0.10713841,  0.01642958,  0.05307269,\n",
       "       -0.02723964, -0.08534575,  0.03214684, -0.19248891, -0.16155324,\n",
       "       -0.11108833, -0.19629939, -0.32957264, -0.07219142,  0.03171135,\n",
       "        0.06655433, -0.0242827 , -0.43275736, -0.10194971, -0.19233679,\n",
       "        0.04247775,  0.15760055, -0.0593703 , -0.0634756 ,  0.07786334,\n",
       "        0.05604188,  0.05113183,  0.03714753,  0.28095996,  0.03223972,\n",
       "        0.20389047, -0.39495083, -0.04235416,  0.03310521, -0.21767165,\n",
       "        0.02381708,  0.37509194,  0.07690634, -0.39798902,  0.38665859,\n",
       "       -0.08774373, -0.0608033 ,  0.28962123, -0.00755525, -0.00383965,\n",
       "        0.03137102, -0.16630992, -0.1711523 ,  0.49549712,  0.087993  ,\n",
       "        0.07263355,  0.30368562,  0.35120757,  0.48119043,  0.05606649,\n",
       "        0.41714664, -0.20836628, -0.47527333,  0.09430114, -0.07594286,\n",
       "        0.26536328, -0.12134169,  0.15247178,  0.24066865,  0.05801503,\n",
       "        0.17051709, -0.16424363, -0.37799297,  0.03537874,  0.19242937,\n",
       "       -0.08429065,  0.15000477,  0.10406453, -0.01696037, -0.40566247,\n",
       "        0.0736307 ,  0.04270691, -0.14408896, -0.20620344,  0.17716223,\n",
       "       -0.00228006, -0.04249882,  0.14998127, -0.19275647, -0.04675555,\n",
       "        0.22293156, -0.62552301,  0.0619657 , -0.01969884,  0.08595939,\n",
       "        0.09859344,  0.13340477, -0.07264688, -0.53546072,  0.02884299,\n",
       "       -0.12112249,  0.19062196,  0.15397197,  0.54361562,  0.17168535])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_ft_wv[\"интернет\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellId": "getll261lfo7wx7duh8hf"
   },
   "outputs": [],
   "source": [
    "def get_w2vembed_and_ftembed(file_name):\n",
    "    questions = []\n",
    "    with open(file_name, \"r\", encoding='utf-8', errors='ignore') as f:\n",
    "        for line in tqdm(f):\n",
    "            spls = line.split(\"\\t\")\n",
    "            questions.append(preprocess_txt(spls[0]))\n",
    "            \n",
    "    modelW2V = Word2Vec(sentences=questions, size=w2v_width, window=5, min_count=1, workers=core_numbers)\n",
    "#     modelFT = FastText(sentences=questions, size=w2v_width, min_count=1, window=5, workers=core_numbers)\n",
    "    \n",
    "#     modelW2V.save(\"word2vec.model\")\n",
    "    modelW2V.wv.save_word2vec_format('word2vec_wv.bin', binary=True)\n",
    "#     modelW2V.wv.save(\"word2vec_wv.kv\")\n",
    "    model_w2v_wv = modelW2V.wv\n",
    "    del modelW2V\n",
    "\n",
    "#     modelFT.save(\"fasttext.model\")\n",
    "#     modelFT.wv.save_word2vec_format('fasttext_wv.bin', binary=True)\n",
    "#     model_ft_wv = modelFT.wv\n",
    "#     del modelFT\n",
    "            \n",
    "    return model_w2v_wv # , model_ft_wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellId": "g99gygu17ldy6o104k1g4"
   },
   "outputs": [],
   "source": [
    "if not flag_w2v: # or not flag_ft:\n",
    "    model_w2v_wv = get_w2vembed_and_ftembed(Path(\"prepared_answers.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellId": "vwb4n8wlq7mf6x0ess6ztn"
   },
   "outputs": [],
   "source": [
    "# modelW2V.wv.save_word2vec_format('word2vec_wv.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "cellId": "nyzqed4zk49pl6adwedd8a"
   },
   "outputs": [],
   "source": [
    "w2v_index = annoy.AnnoyIndex(w2v_width ,'angular')\n",
    "ft_index = annoy.AnnoyIndex(ft_width ,'angular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "cellId": "w6m41kcz9tk1z7c0m2p6"
   },
   "outputs": [],
   "source": [
    "# flag_index_map = False\n",
    "flag_w2v_index = False\n",
    "flag_ft_index = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "cellId": "9q7u4rq8lwkhornd8q3s3"
   },
   "outputs": [],
   "source": [
    "# index_map = {}\n",
    "\n",
    "# index_file = Path(\"index_map.pickle\")\n",
    "# if index_file.is_file():\n",
    "#     with open('index_map.pickle', 'rb') as f:\n",
    "#         index_map = pickle.load(f)\n",
    "#     flag_index_map = True\n",
    "\n",
    "w2v_index_file = Path(\"w2v_index.ann\")\n",
    "if w2v_index_file.is_file():\n",
    "    w2v_index.load(\"w2v_index.ann\")\n",
    "    flag_w2v_index = True\n",
    "\n",
    "ft_index_file = Path(\"ft_index.ann\")\n",
    "if ft_index_file.is_file():\n",
    "    ft_index.load(\"ft_index.ann\")\n",
    "    flag_ft_index = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "cellId": "j6d9peh762h8tbdrf1k8po"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.keyedvectors.FastTextKeyedVectors"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "type(model_ft_wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellId": "4l6o7qbdefedbvabof2zl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1163342it [1:46:54, 181.36it/s]\n"
     ]
    }
   ],
   "source": [
    "if not flag_w2v_index or not flag_ft_index:  # or not flag_index_map:\n",
    "    counter = 0\n",
    "\n",
    "    with open(\"prepared_answers.txt\", \"r\", encoding='utf-8', errors='ignore') as f:\n",
    "        for line in tqdm(f):\n",
    "            n_w2v = 0\n",
    "            n_ft = 0\n",
    "            spls = line.split(\"\\t\")\n",
    "#             index_map[counter] = spls[1]\n",
    "            question = preprocess_txt(spls[0])\n",
    "\n",
    "            vector_w2v = np.zeros(w2v_width)\n",
    "            vector_ft = np.zeros(ft_width)\n",
    "            for word in question:\n",
    "                if word in model_w2v_wv:\n",
    "                    vector_w2v += model_w2v_wv[word]\n",
    "                    n_w2v += 1\n",
    "                if word in model_ft_wv:\n",
    "                    vector_ft += model_ft_wv[word]\n",
    "                    n_ft += 1\n",
    "            if n_w2v > 0:\n",
    "                vector_w2v = vector_w2v / n_w2v\n",
    "            if n_ft > 0:\n",
    "                vector_ft = vector_ft / n_ft\n",
    "            w2v_index.add_item(counter, vector_w2v)\n",
    "            ft_index.add_item(counter, vector_ft)\n",
    "\n",
    "            counter += 1\n",
    "#             if counter > 1800000:\n",
    "#                 break\n",
    "#             if not counter % 10000:\n",
    "#                 print(counter)\n",
    "\n",
    "    w2v_index.build(20)\n",
    "    ft_index.build(20)\n",
    "#     with open('index_map.pickle', 'wb') as fl:\n",
    "#         pickle.dump(index_map, fl)\n",
    "    w2v_index.save('w2v_index.ann')\n",
    "    ft_index.save('ft_index.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cellId": "sh5p3ajfjypkof880ykz"
   },
   "outputs": [],
   "source": [
    "# with open('index_map.pickle', 'wb') as fl:\n",
    "#     pickle.dump(index_map, fl)\n",
    "\n",
    "# w2v_index.save('w2v_index.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "cellId": "4e1w9a2y6ff4k1m1rk97pw"
   },
   "outputs": [],
   "source": [
    "def get_response(question, index, model, width):\n",
    "    question = preprocess_txt(question)\n",
    "    vector = np.zeros(width)\n",
    "    norm = 0\n",
    "    for word in question:\n",
    "        if word in model:\n",
    "            vector += model[word]\n",
    "            norm += 1\n",
    "    if norm > 0:\n",
    "        vector = vector / norm\n",
    "    line_numbers = index.get_nns_by_vector(vector, 3)\n",
    "    print(line_numbers)\n",
    "#     f = open(\"prepared_answers.txt\", \"r\", encoding='utf-8', errors='ignore')\n",
    "    spls = [getline(\"prepared_answers.txt\", i+1).split(\"\\t\") for i in line_numbers]\n",
    "    for spl in spls:\n",
    "        print(f\"Вопрос: {spl[0]}\\nОтвет: {spl[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "cellId": "zd7wi90j2ce4h33ld8959"
   },
   "outputs": [],
   "source": [
    "TEXT = \"как подключить интернет\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellId": "470tj50nmumgn2n7u7jevs"
   },
   "outputs": [],
   "source": [
    "get_response(TEXT, w2v_index, model_w2v_wv, w2v_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cellId": "qe80cvugbfjqw6arsekgvl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[68591, 254030, 91982]\n",
      "Вопрос: в каком году подключились к интернету? .\n",
      "Ответ: 2009 год. \n",
      "\n",
      "Вопрос: как подключиться к интернету? .\n",
      "Ответ: Нада проверить для начала сеть-220В!!!. \n",
      "\n",
      "Вопрос: интернет xl подключить .\n",
      "Ответ: Бери и подключи интернет xl. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_response(TEXT, ft_index, model_ft_wv, ft_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cellId": "irbv46veufl67b7vxe30s8"
   },
   "outputs": [],
   "source": [
    "TEXT = \"как починить машину\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cellId": "hcstwri9qt7most793fcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[933221, 909274, 869716]\n",
      "Вопрос: как чинить машины .\n",
      "Ответ: ручками.. . ручками.... \n",
      "\n",
      "Вопрос: нужно ли прогревать инжекторную машину? .\n",
      "Ответ: Если не хотите, чтобы она проела дыру в вашем бюджете - то обязательно.. . Особенно если у нее автомат.... \n",
      "\n",
      "Вопрос: что значит машина задута .\n",
      "Ответ: если задутая то не советую брать. Скорее всего битая, правленая и полностью покрашеная чтобы слой краски везде был одинаковым и прозвонкой не проверить было битая или нет.. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_response(TEXT, w2v_index, model_w2v_wv, w2v_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cellId": "65cnonyyywp2hj9nrssntj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[933221, 266597, 119797]\n",
      "Вопрос: как чинить машины .\n",
      "Ответ: ручками.. . ручками.... \n",
      "\n",
      "Вопрос: Щебнеочистительная машина.\n",
      "Ответ: <p>Щебнеочисти́тельная маши́на — путевая машина для очистки балласта, применяемая на железнодорожном транспорте при среднем и капитальном ремонте железнодорожного пути для восстановления упругости щебёночного слоя и его дренирующих свойств, а также для улучшения несущей способности балластной призмы.</p>   <h2>История появления</h2> <p>Первые щебнеочистительные машины были созданы в СССР в 40-х годах XX века, а на железнодорожном ходу — в начале 1950-х годов. Машины на железнодорожном ходу выполняли очистку щебня по всей ширине балластной призмы: балласт забирался с пути ковшовыми цепями и подавался в цилиндрические вращающиеся грохоты, через отверстия которых загрязнители и мелкие (пылевые) фракции щебня падали на конвейер и выбрасывались на обочину пути. Очищенный балласт ссыпался в путь. Внедрение прогрессивной технологии, при которой машины тяжёлого типа в определённой последовательности выполняют ремонт пути в «окна», потребовало разработки принципиально новой машины, работающей с большей производительностью. С середины 1950-х годов выпускаются самоходные щебнеочистительные машины на базе электробалластёра и полуприцепные, работающие с одним или двумя тракторами. На всех щебнеочистительных машинах используется центробежное щебнеочистительное устройство, предложенное А. М. Драгавцевым.</p> <h2>Конструкция и технология очистки</h2> <p>Щебнеочистительное устройство состоит из двух помещённых одна в другую, замкнутых лент. Внутренняя сетчатая и внешняя сплошная ленты движутся перпендикулярно оси пути над подрезным ножом, заглублённым в балласт на 25 сантиметров. Срезаемый ножом щебень поступает на сетчатую ленту, через ячейки которой на криволинейном участке мелкие фракции и пыль под действием центробежной силы выбрасываются на наружную сплошную ленту и по ней ссыпаются на конвейер. Очищенный щебень по другому конвейеру попадает обратно в путь. Кроме оборудования электробалластёра (устройств для подъёма и сдвижки рельсо-шпальной решётки, выправки профиля пути, подбивки шпальных ящиков) на щебнеочистительной машине имеется щебнеотборочное устройство, предотвращающее переподъёмку путевой решётки (превышение высоты подъёмки сверх проектной). Щебнеочистительная машина снабжена также ковшовыми роторами, которые предназначены для вырезки щебня за торцами шпал и прокладки траншей, уменьшающих сопротивление движению подрезного ножа и крыльев. Щебнеочистительные машины на однопролётной раме оборудованы дополнительным конвейером, по которому загрязнители поступают в землеуборочный состав. Конвейер может поворачиваться и располагаться поперёк пути, что позволяет также использовать щебнеочистительные машины при работе у высоких платформ. Производительность щебнеочистительных машин до 3000 кубических метров балласта в час, глубина очистки щебеночного слоя до 40 сантиметров.</p> <h2>Типы щебнеочистителей</h2> <ul> <li>Самоходные щебнеочистительные машины, работающие без подъёма рельсо-шпальной решётки, используются для очистки балласта под стрелочными переводами на станционных путях и перегонах, а также у высоких платформ. Кроме щебнеочистительного устройства центробежного типа на щебнеочистительных машинах имеются выгребные устройства (скребковые цепные механизмы), конвейеры для выноса загрязнителей, дозатор балласта, очищающие рельсовые и шпальные щётки. Применяются выгребные устройства с укороченными зубьями цепи (для работы на перегонах) и с удлинёнными зубьями (на стрелочных переводах). Производительность такой щебнеочистительные машины до 300 кубических метров балласта в час.</li> <li>Полуприцепные щебнеочистительные машины используются при капитальном ремонте пути для очистки, уплотнения и планировки балласта. Оборудование смонтировано на раме, связанной с трактором через упряжное устройство и тяговую раму трактора. Задняя часть рамы опирается на два катка. Балласт, вырезаемый подрезным ножом, подаётся в щебнеочистительное устройство боковыми крыльями. Очищенный балласт разравнивается по всей ширине балластной призмы плужным планировщиком. Производительность щебнеочистительной машины до 1200 кубических метров балласта в час.</li> </ul> <h2>В России</h2> <p>Современные щебнеочистительные машины поднимают рельсо-шпальную решётку и производят вырезку балласта под ним и очистку его от загрязнений, очищенный щебень разравнивается равномерно по ширине пути. Созданы щебнеочистительные машины, включаемые в путевые комплексы, состоящие из машин, работающих с высокими рабочими скоростями, осуществляющими вырезку балласта и погрузку его на подвижной состав, а также очистку щебня на всю его глубину при любых поперечных профилях балластной призмы. Загрязнитель перемещается транспортёрной лентой щебнеочистительной машины и выбрасывается за пределы пути.</p> <h2>В мире</h2> <p>Выпускаемые для железных дорог мира самоходные щебнеочистительные машины имеют скребковые или ковшовые выгребные устройства. Для очистки щебня часто используются виброгрохоты. Такие щебнеочистительные машины обеспечивают большую глубину очистки, но имеют более низкую производительность, чем щебнеочистительные машины с центробежным способом очистки балласта. Компания Plasser &amp; Theurer выпускает также высокопроизводительную машину RM 95-700 для очистки балласта через сдвоенный грохот. Эта восьмиосная балластоочистительная машина сочлененной конструкции с гидравлическим приводом и запасом нового балласта отличается высокой производительностью и компактностью конструкции. RM 95-700 используется в различных условиях и представляет собой новую модель, которую можно классифицировать как промежуточную между машинами серии RM 800/RM 900 и RM 80.</p> <h2>Примечания</h2> <h2>См. также</h2> <ul> <li>СЧ-600</li> <li>Баровая машина</li> </ul> <h2>Литература</h2> <ul> <li>Щебнеочистительная машина // Железнодорожный транспорт: Энциклопедия / Гл. ред. Н. С. Конарев. — М.: Большая Российская энциклопедия, 1994. — С. 502. — ISBN 5-85270-115-7.</li> </ul>. \n",
      "\n",
      "Вопрос: очень хочу машину посудомоечную...,может скинетесь.. .\n",
      "Ответ: Готов поучавствовать, ужином угостишь? А ты в курсе, что прежде чем в ней мыть посуду, ее надо сначала очистить от остатков пищи, т.е. вымыть :) Да и расходные материалы для мытья в машине не дешевы.. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_response(TEXT, ft_index, model_ft_wv, ft_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cellId": "esns9ucm778h8rel7iw1j6"
   },
   "outputs": [],
   "source": [
    "TEXT = \"какую почитать книгу\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cellId": "xpd7idw6l5ag481c7rnmn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[928332, 199643, 287400]\n",
      "Вопрос: Про что бы вы почитали книгу? .\n",
      "Ответ: Про путешествия.. \n",
      "\n",
      "Вопрос: Какую книгу можно почитать про оккультизм? .\n",
      "Ответ: Папюс \"Черная магия\". \n",
      "\n",
      "Вопрос: У кого есть такая книга?) Одолжите почитать? .\n",
      "Ответ: Наш человек растет!. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_response(TEXT, w2v_index, model_w2v_wv, w2v_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cellId": "u432oe4wxzkgm03d927vd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[928332, 924643, 932711]\n",
      "Вопрос: Про что бы вы почитали книгу? .\n",
      "Ответ: Про путешествия.. \n",
      "\n",
      "Вопрос: Какую можно почитать интересную книгу? .\n",
      "Ответ: советую - Марк Леви - Где ты - и отдахнешь под нее и попереживаешь<br>А вообще прочитай отзывы о книгах на форуме в эл. библиотеке - поймешь чего хочешь и книгу скачаешь бесплатно - например http://www.aldebaran.ru/. \n",
      "\n",
      "Вопрос: Какую книгу про японию почитать? .\n",
      "Ответ: Конечно если найдете, то по моему лучше всего - книги А.Н. Мещерякова:\"Быть японцем\", \"Книга японских символов\", \"Книга японских обыкновений\". Так же - ставший уже почти классическим труд Р. Бенедикт \"Хризантема и меч\" и \"Ветку сакуры\" В. Овчинникова. Кое что можно почерпнуть и из \"Пятнадцатый камень сада Рёандзи\" В. Цветова.. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_response(TEXT, ft_index, model_ft_wv, ft_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "x4xyqek831c7iuqumk6qka"
   },
   "source": [
    "## Сохраняем модель на Яндекс диск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "cellId": "fui7mdv6ljk2by2jhlzpf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ml_kernel/kernel.py:442: UserWarning: The following variables cannot be serialized: disk\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from cloud_ml.storage.api import Storage\n",
    "\n",
    "# To retrieve application id and secret:\n",
    "# 1. Go to link: https://oauth.yandex.ru/client/new\n",
    "# 2. Choose 'Web services'\n",
    "# 3. Paste into 'Callback URI': https://oauth.yandex.ru/verification_code\n",
    "# 4. Set up permissions on yandex disk\n",
    "disk = Storage.ya_disk(application_id='8b22c6d569724e6b92646b7d6d2a3953', application_secret='b2b380d359a54802be5c27e2360e2c08')\n",
    "\n",
    "# uploading contents of the local file into the remote one\n",
    "# disk.put('word2vec_wv.bin', 'Jupyter/NLP/full_300/word2vec_wv.bin')\n",
    "# disk.put('fasttext_wv.bin', 'Jupyter/NLP/full_300/fasttext_wv.bin')\n",
    "# disk.put('word2vec.model', 'Jupyter/NLP/m500k/word2vec.model')\n",
    "# disk.put('word2vec.model.trainables.syn1neg.npy', 'Jupyter/NLP/m500k/word2vec.model.trainables.syn1neg.npy')\n",
    "# disk.put('word2vec.model.wv.vectors.npy', 'Jupyter/NLP/m500k/word2vec.model.wv.vectors.npy')\n",
    "# disk.put('w2v_index.ann', 'Jupyter/NLP/full_300/w2v_index.ann')\n",
    "disk.put('ft_index.ann', 'Jupyter/NLP/full_300/ft_index.ann')\n",
    "# disk.put('index_map.pickle', 'Jupyter/NLP/m1800k/index_map.pickle')\n",
    "disk.put('prepared_answers2.txt', 'Jupyter/NLP/prepared_answers2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "xap31sck3ylh67ybffq5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "notebookId": "1c321f5f-d906-438b-9d72-7a7817b9ee83"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
